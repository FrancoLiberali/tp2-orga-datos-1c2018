{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "avisos_detalle = pd.read_csv('../orga-datos/datos_preprocesados/fiuba_6_avisos_detalle.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cantidad_de_palabras_que_quiero = 500\n",
    "porcetaje=0.01\n",
    "similitud=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from descripcion_parser import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopswords=\"a acá ahí ajena ajeno ajenos ajenas al algo algún algúna algúno algúnos algúnas allá allí ambos ante antes aquel aquella aquello aquellos aquellas aquí arriba así atrás aun aunque bajo bastante bien cabe cada casi cierto cierta ciertos ciertas como con conmigo conseguimos conseguir consigo consigue consiguen consigues contigo contra cual cuales cualquier cualquiera cualquieras cuancuando cuanto cuantas cuanta cuantos de dejar del demás demasiada demasiadas demasiado demasiados dentro desde donde dos e el él ella ellas ello ellos empleáis emplean emplear empleas empleo en encima entonces entre era eras eramos eran eres es esa ese eso esos esas esta estas estaba estado estáis estamos están estar este esto estos estas estoy etc fin fue fueron fui fuimos gueno ha hace haces hacéis hacemos hacen hacer hacia hago hasta incluso intenta intentas intentáis intentamos intentan intentar intento ir jamás junto juntos la lo las los largo más me menos mi mis mía mías mientras mío míos misma mismo mismos mismas modo mucha muchas muchísima muchísimos muchísimo muchísimas mucho muchos muy nada ni ningún ningúna ningúnas ningúno ningúnos no nos nosotras nosotros nuestra nuestro nuestros nuestras nunca o os otra otro otras otros para parecer pero poca poco pocas pocos podéis podemos poder podría podrías podríais podríamos podrían por por qué porque primero puede pueden puedo pues que qué querer quién quiénes quienesquiera quienquiera quizá quizás sabe sabes saben sabéis sabemos saber se según ser si sí siempre siendo sin sino so sobre sois solamente solo sólo somos soy sr sra sres sta su sus suyo suyos suya suyas tal tales también tampoco tan tanta tanto tantos tantas te tenéis tenemos tener tengo ti tiempo tiene tienen todo todos toda todas tomar trabaja trabajo trabajáis trabajamos trabajan trabajar trabajas tras tú tu tus tuya tuyas tuyo tuyos último ultimo un una unas uno unos usa usas usáis usamos usan usar uso usted ustedes va van vais valor vamos varias varios vaya verdadera vosotras vosotros voy vuestra vuestros vuestro vuestras y ya yo como donde requisitos requisito buscamos importante buenas muy grandes beneficios encontramos busqueda zona \"\n",
    "stopswords=stopswords.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stop_words import ESP_STOP_WORDS as BASE_STOP_WORDS, ENG_STOP_WORDS\n",
    "\n",
    "stopswords = set([ \n",
    " 'preferentemente'\n",
    "]).union(BASE_STOP_WORDS.union(ENG_STOP_WORDS).union(stopswords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from html.parser import HTMLParser\n",
    "\n",
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        self.strict = False\n",
    "        self.convert_charrefs= True\n",
    "        self.fed =[]\n",
    "    def handle_data(self, d):\n",
    "        self.fed.append(d)\n",
    "    def get_data(self):\n",
    "        return ' '.join(self.fed)\n",
    "\n",
    "def strip_html_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()\n",
    "\n",
    "def foldear_simbolos(cadena):\n",
    "    ''' \n",
    "    Elimina los acentos de una cadena en minúsculas. \n",
    "    Ej: descripción -> descripcion\n",
    "    '''\n",
    "    acentos = {'á':'a', 'é':'e', 'í':'i', 'ó':'o', 'ú':'u', 'ü':'u'}\n",
    "    cadena = list(cadena)\n",
    "    for i in range(len(cadena)):\n",
    "        if not cadena[i].isalpha():\n",
    "            cadena[i] = ' '\n",
    "        else:\n",
    "            cadena[i] = acentos.get(cadena[i], cadena[i])\n",
    "    \n",
    "    return ''.join(cadena)\n",
    "\n",
    "def es_palabra_inutil(palabra):\n",
    "    '''\n",
    "    Devuelve True si palabra es una palabra que no aporta\n",
    "    contenido.\n",
    "    '''\n",
    "    return palabra in set(stopswords)\n",
    "\n",
    "def parse(descripcion):\n",
    "    '''\n",
    "    Normaliza una descripción de aviso del set de datos de Navent.\n",
    "    Elimina tags HTML, pasa a minúsculas y la convierte a tokens.\n",
    "    '''\n",
    "    resultado = []\n",
    "    \n",
    "    for palabra in strip_html_tags(descripcion).lower().split():\n",
    "        if es_palabra_inutil(palabra):\n",
    "            continue\n",
    "            \n",
    "        resultado.extend(foldear_simbolos(palabra).split())\n",
    "    \n",
    "    return ' '.join(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "words={}\n",
    "def total_freq(description):\n",
    "    #it create a dictionary with the following format (word : #appearances in the sum of descriptions)\n",
    "    words_processed=[]\n",
    "    for word in description.split():\n",
    "        if word not in words_processed:\n",
    "            words[word] = words.get(word, 0) + 1\n",
    "            words_processed.append(word)\n",
    "    return description\n",
    "\n",
    "factor = avisos_detalle[\"descripcion\"].count()*porcetaje #aca va el porcentaje que se quiere tener\n",
    "\n",
    "def remove_less_frequent_words(description):\n",
    "    # we will remove all the words which appear in less than 1% of the descrptions\n",
    "    result = []\n",
    "    for word in description.lower().split():\n",
    "        if words[word] < factor:\n",
    "            continue\n",
    "            \n",
    "        result.append(word)\n",
    "    \n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "avisos_detalle[\"descripcion\"]=avisos_detalle[\"descripcion\"].map(parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Stemmer\n",
    "\n",
    "stemmer = Stemmer.Stemmer('spanish')\n",
    "raices={}\n",
    "\n",
    "def conseguir_raices(descripcion):\n",
    "    \n",
    "    for palabra in descripcion.lower().split():\n",
    "        if palabra in raices:\n",
    "            continue\n",
    "        p=stemmer.stemWords([palabra])\n",
    "        raices[palabra]=p[0]\n",
    "    return descripcion\n",
    "    \n",
    "def reempazar_por_raiz(description):\n",
    "    \n",
    "    result = []\n",
    "    for word in description.lower().split():\n",
    "        word=raices[word]    \n",
    "        result.append(word)\n",
    "    \n",
    "    return ' '.join(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "avisos_detalle[\"descripcion\"]=avisos_detalle[\"descripcion\"].map(conseguir_raices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "avisos_detalle[\"descripcion\"]=avisos_detalle[\"descripcion\"].map(reempazar_por_raiz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "avisos_detalle[\"descripcion\"]=avisos_detalle[\"descripcion\"].map(total_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "avisos_detalle[\"descripcion\"] = avisos_detalle[\"descripcion\"].map(remove_less_frequent_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Jaccard for data1 and data2 is 1.0\n",
      "busqued anal credit jr sector entid bancari posicion respons ser analisis evaluacion propuest credit participacion conjunt credit administracion carter requisit postulat si sos profesional estudi avanz carrer cienci econom licenci administracion ingenier ten actitud proactiv manej relacion interpersonal equip orientacion result cont manej paquet offic valor conoc segment experient laboral analisis balanc riesg credit benefici condicion contratacion lun viern jorn tim trabaj microcentr empres ofrec condicion contratacion\n",
      "Estimated Jaccard for data1 and data2 is 0.3046875\n",
      "busqued un estudi carrer cienci econom desempeñ anal junior administracion finanz principal tar ser participacion proces pag proveedor emision valor fisic y o electron confeccion legaj pag proveedor cambi gast estructur confeccion administracion fond fij pag viaj otras busqued orient person agil dinam capac organizacion relacion interpersonal aprend desarroll are ser excluyent cont nivel avanz paquet offic valor cont experient posicion similar ofrec excelent condicion contratacion desarroll trabaj cab jorn laboral lun viern hs hs postulat\n",
      "Estimated Jaccard for data1 and data2 is 0.546875\n",
      "busqued lid cobranz compañi financ grup reconoc entid bancari posicion respons ser organiz grup tare indic seguimient report postulat si sos profesional estudi carrer cienci econom afin ten actitud proactiv manej relacion interpersonal orientacion result cont manej paquet offic valor conoc manej sistem condicion contratacion lun viern jorn tim trabaj microcentr\n",
      "Estimated Jaccard for data1 and data2 is 0.328125\n",
      "busqued anal gerenci analisis credit empres perfil requer profesional estudi avanz cienci econom contador public manej relacion interpersonal equip actitud proactiv orientacion result valor experient laboral y o estudi tem nivel ingles intermedi pos conoc herramient microsoft offic principal respons administracion carter client credit analisis opinion propuest credit flu interaccion are comercial cumplis perfil experient requer postulat\n",
      "Estimated Jaccard for data1 and data2 is 0.3515625\n",
      "empres multinacional busqued anal jr respons ser gestion seguimient cobranz control recib valor recib deposit analisis cuent movimient requisit estudi avanz carrer cs econom afin excluyent manej sistem sap excluyent nivel ingles avanz excluyent trabaj jorn laboral lun viern tim contratacion eventual posibil efectivizacion\n",
      "Estimated Jaccard for data1 and data2 is 0.3046875\n",
      "busqued anal model decision sector desarroll administracion model conoc banc priv posicion respons ser desarroll manten implementacion model analit avanz estadist variabl asist tom decision seguimient model implement cumpl norm realizacion analisis propuest permit riesg proces postulat si sos gradu proxim carrer estadist ingenieri carrer relacion dat dat dat dat cont experient analisis interpretacion dat valor experient are simil generacion model dat empres ofrec condicion contratacion\n",
      "Estimated Jaccard for data1 and data2 is 0.3046875\n",
      "busqued un estudi carrer cienci econom desempeñ anal junior gerenci finanz principal tar ser participacion proces pag proveedor emision valor fisic y o electron confeccion legaj pag proveedor cambi gast estructur confeccion administracion fond fij pag viaj otras busqued orient person agil dinam capac organizacion relacion interpersonal aprend desarroll are ser excluyent cont nivel avanz paquet offic valor cont experient posicion similar ofrec excelent condicion contratacion desarroll trabaj cab jorn laboral lun viern hs hs postulat\n",
      "Estimated Jaccard for data1 and data2 is 0.3046875\n",
      "empres ubic busqued estudi ingenieri industrial logist cubr posicion anal jr logist cont experient comprob posicion similar principal funcion encontr siguient analisis proces oper vigent futur desarroll proces centr distribucion desarroll plan correspondient excelent manej autoc inform analisis oper implementacion propuest mejor valor conoc tecnic proactiv organizacion relacion interpersonal jorn trabaj lun viern tim trabaj\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "# sudo pip3 install datasketch -U\n",
    "\n",
    "from datasketch import MinHash\n",
    "\n",
    "#te da lasdescripciones que tengan semejanza mayor a 0.3 (este es un buen factor)\n",
    "\n",
    "data1=avisos_detalle[\"descripcion\"][43]\n",
    "data1=data1.split()\n",
    "    \n",
    "def jac(texto):\n",
    "    \n",
    "    data2=texto.split()\n",
    "    m1, m2 = MinHash(), MinHash()\n",
    "    for d in data1:\n",
    "        m1.update(d.encode('utf8'))\n",
    "    for d in data2:\n",
    "        m2.update(d.encode('utf8'))\n",
    "    if m1.jaccard(m2)> similitud:     \n",
    "        print(\"Estimated Jaccard for data1 and data2 is\", m1.jaccard(m2))\n",
    "        print(\" \".join(data2))\n",
    "\n",
    "d=avisos_detalle[\"descripcion\"].map(jac)  \n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from scipy.sparse.csr import csr_matrix #need this if you want to save tfidf_matrix\n",
    "\n",
    "#tf = TfidfVectorizer(input='/home/iglesias/test', analyzer='word', ngram_range=(1,6),\n",
    "#min_df = 0, stop_words = 'english', sublinear_tf=True)\n",
    "tf = TfidfVectorizer() \n",
    "tfidf_matrix =  tf.fit_transform(avisos_detalle[\"descripcion\"])\n",
    "\n",
    "\n",
    "feature_names = tf.get_feature_names()\n",
    "\n",
    "\"\"\"doc =0\n",
    "feature_index = tfidf_matrix[doc,:].nonzero()[1]\n",
    "tfidf_scores = zip(feature_index, [tfidf_matrix[doc, x] for x in feature_index])\n",
    "for w, s in [(feature_names[i], s) for (i, s) in tfidf_scores]:\n",
    "  print(w, s)\n",
    "\"\"\"\n",
    "factor=avisos_detalle[\"descripcion\"].count()\n",
    "\n",
    "scores=[]\n",
    "dos_mil_palabras_importantes = []\n",
    "for doc in range(factor):\n",
    "    feature_index = tfidf_matrix[doc,:].nonzero()[1]\n",
    "    tfidf_scores = zip(feature_index, [tfidf_matrix[doc, x] for x in feature_index])\n",
    "    for w, s in [(feature_names[i], s) for (i, s) in tfidf_scores]:\n",
    "      if not w in dos_mil_palabras_importantes:   \n",
    "          scores.append(-s)\n",
    "          dos_mil_palabras_importantes.append(w)  \n",
    "\n",
    "import heapq\n",
    "\n",
    "scores_mas_importantes=[]\n",
    "heapq.heapify(scores)\n",
    "puntajes_de_palabras={}\n",
    "cantidad_de_palabras_que_quiero = 500 #fijarse de tener esta cantidad de palabras sino rompe\n",
    "\n",
    "for x in range(cantidad_de_palabras_que_quiero):\n",
    "    scores_mas_importantes.append(heapq.heappop(scores))\n",
    "\n",
    "dos_mil_palabras_importantes = []    \n",
    "    \n",
    "for doc in range(avisos_detalle[\"descripcion\"].count()):\n",
    "    feature_index = tfidf_matrix[doc,:].nonzero()[1]\n",
    "    tfidf_scores = zip(feature_index, [tfidf_matrix[doc, x] for x in feature_index])\n",
    "    for w, s in [(feature_names[i], s) for (i, s) in tfidf_scores]:\n",
    "      puntajes_de_palabras[w]=s  \n",
    "      if -s in scores_mas_importantes:   \n",
    "          dos_mil_palabras_importantes.append(w) \n",
    "            \n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'busqued anal credit jr sector entid bancari posicion respons ser analisis evaluacion propuest credit participacion conjunt credit administracion carter requisit postulat si sos profesional estudi avanz carrer cienci econom licenci administracion ingenier ten actitud proactiv manej relacion interpersonal equip orientacion result cont manej paquet offic valor conoc segment experient laboral analisis balanc riesg credit benefici condicion contratacion lun viern jorn tim trabaj microcentr empres ofrec condicion contratacion'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2=avisos_detalle[\"descripcion\"][43]\n",
    "data2#nuevo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mas_impor(description):\n",
    "    \n",
    "    resultado = []\n",
    "    \n",
    "    for palabra in description.lower().split():\n",
    "        if palabra not in dos_mil_palabras_importantes:\n",
    "            continue\n",
    "            \n",
    "        resultado.append(palabra)\n",
    "    \n",
    "    return ' '.join(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "avisos_detalle[\"descripcion\"]=avisos_detalle[\"descripcion\"].map(mas_impor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        None\n",
       "1        None\n",
       "2        None\n",
       "3        None\n",
       "4        None\n",
       "5        None\n",
       "6        None\n",
       "7        None\n",
       "8        None\n",
       "9        None\n",
       "10       None\n",
       "11       None\n",
       "12       None\n",
       "13       None\n",
       "14       None\n",
       "15       None\n",
       "16       None\n",
       "17       None\n",
       "18       None\n",
       "19       None\n",
       "20       None\n",
       "21       None\n",
       "22       None\n",
       "23       None\n",
       "24       None\n",
       "25       None\n",
       "26       None\n",
       "27       None\n",
       "28       None\n",
       "29       None\n",
       "         ... \n",
       "25258    None\n",
       "25259    None\n",
       "25260    None\n",
       "25261    None\n",
       "25262    None\n",
       "25263    None\n",
       "25264    None\n",
       "25265    None\n",
       "25266    None\n",
       "25267    None\n",
       "25268    None\n",
       "25269    None\n",
       "25270    None\n",
       "25271    None\n",
       "25272    None\n",
       "25273    None\n",
       "25274    None\n",
       "25275    None\n",
       "25276    None\n",
       "25277    None\n",
       "25278    None\n",
       "25279    None\n",
       "25280    None\n",
       "25281    None\n",
       "25282    None\n",
       "25283    None\n",
       "25284    None\n",
       "25285    None\n",
       "25286    None\n",
       "25287    None\n",
       "Name: idaviso, Length: 25288, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_av={}\n",
    "\n",
    "def dic(a):\n",
    "    l=[]\n",
    "    for x in range(500):\n",
    "        l.append(0)\n",
    "    id_av[a]=l\n",
    "\n",
    "avisos_detalle[\"idaviso\"].map(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(id_av[1001284385])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index={}\n",
    "contador = [0]\n",
    "def index_words(description):\n",
    "\n",
    "    for w in description.split():\n",
    "        if w not in word_index:\n",
    "            word_index[w] = contador[0]\n",
    "            contador[0] = contador[0] +1 \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        None\n",
       "1        None\n",
       "2        None\n",
       "3        None\n",
       "4        None\n",
       "5        None\n",
       "6        None\n",
       "7        None\n",
       "8        None\n",
       "9        None\n",
       "10       None\n",
       "11       None\n",
       "12       None\n",
       "13       None\n",
       "14       None\n",
       "15       None\n",
       "16       None\n",
       "17       None\n",
       "18       None\n",
       "19       None\n",
       "20       None\n",
       "21       None\n",
       "22       None\n",
       "23       None\n",
       "24       None\n",
       "25       None\n",
       "26       None\n",
       "27       None\n",
       "28       None\n",
       "29       None\n",
       "         ... \n",
       "25258    None\n",
       "25259    None\n",
       "25260    None\n",
       "25261    None\n",
       "25262    None\n",
       "25263    None\n",
       "25264    None\n",
       "25265    None\n",
       "25266    None\n",
       "25267    None\n",
       "25268    None\n",
       "25269    None\n",
       "25270    None\n",
       "25271    None\n",
       "25272    None\n",
       "25273    None\n",
       "25274    None\n",
       "25275    None\n",
       "25276    None\n",
       "25277    None\n",
       "25278    None\n",
       "25279    None\n",
       "25280    None\n",
       "25281    None\n",
       "25282    None\n",
       "25283    None\n",
       "25284    None\n",
       "25285    None\n",
       "25286    None\n",
       "25287    None\n",
       "Name: descripcion, Length: 25288, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avisos_detalle[\"descripcion\"].map(index_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "print(len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1=avisos_detalle.groupby(\"idaviso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for Id,desc in test1:\n",
    "    l=id_av[Id]\n",
    "    for w in ((desc[\"descripcion\"].values)[0]).split():\n",
    "        l[word_index[w]]=l[word_index[w]] + puntajes_de_palabras[w]\n",
    "    id_av[Id]=l "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1616363816347445, 0.070889533039060135, 0.082544515981039734, 0.093297825346971938, 0.239900128245956, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(id_av[1001284385])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "avisos_con_palabras=0\n",
    "for aviso in id_av:\n",
    "    for x in id_av[aviso]:\n",
    "        if x != 0:\n",
    "            avisos_con_palabras +=1\n",
    "            break\n",
    "\n",
    "avisos_sin_visitas=len(id_av)-avisos_con_palabras            \n",
    "print(avisos_sin_visitas)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_name=[]\n",
    "for x in range(500):\n",
    "    columns_name.append(\" \")\n",
    "for x in word_index:\n",
    "    columns_name[word_index[x]]=x  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('../orga-datos/words_in_description.csv', 'w') as salida:\n",
    "        wrt = csv.writer(salida)\n",
    "        columns_name.insert(0,\"idaviso\")\n",
    "        wrt.writerow(columns_name)\n",
    "        for iD in id_av:\n",
    "            l=id_av[iD]\n",
    "            l.insert(0, iD)\n",
    "            wrt.writerow(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../orga-datos/words_in_description.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idaviso</th>\n",
       "      <th>estas</th>\n",
       "      <th>interes</th>\n",
       "      <th>grup</th>\n",
       "      <th>ingres</th>\n",
       "      <th>dat</th>\n",
       "      <th>vincul</th>\n",
       "      <th>industri</th>\n",
       "      <th>automotriz</th>\n",
       "      <th>estar</th>\n",
       "      <th>...</th>\n",
       "      <th>munr</th>\n",
       "      <th>autogestion</th>\n",
       "      <th>maquinari</th>\n",
       "      <th>we</th>\n",
       "      <th>join</th>\n",
       "      <th>solutix</th>\n",
       "      <th>lectur</th>\n",
       "      <th>it</th>\n",
       "      <th>pyme</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1112342528</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1111556097</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1112408066</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2399</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1112408072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1112342538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      idaviso  estas  interes  grup  ingres     dat  vincul  industri  \\\n",
       "0  1112342528    0.0      0.0   0.0     0.0  0.0000     0.0       0.0   \n",
       "1  1111556097    0.0      0.0   0.0     0.0  0.0000     0.0       0.0   \n",
       "2  1112408066    0.0      0.0   0.0     0.0  0.2399     0.0       0.0   \n",
       "3  1112408072    0.0      0.0   0.0     0.0  0.0000     0.0       0.0   \n",
       "4  1112342538    0.0      0.0   0.0     0.0  0.0000     0.0       0.0   \n",
       "\n",
       "   automotriz  estar ...   munr  autogestion  maquinari   we  join  solutix  \\\n",
       "0         0.0    0.0 ...    0.0          0.0        0.0  0.0   0.0      0.0   \n",
       "1         0.0    0.0 ...    0.0          0.0        0.0  0.0   0.0      0.0   \n",
       "2         0.0    0.0 ...    0.0          0.0        0.0  0.0   0.0      0.0   \n",
       "3         0.0    0.0 ...    0.0          0.0        0.0  0.0   0.0      0.0   \n",
       "4         0.0    0.0 ...    0.0          0.0        0.0  0.0   0.0      0.0   \n",
       "\n",
       "   lectur   it  pyme  set  \n",
       "0     0.0  0.0   0.0  0.0  \n",
       "1     0.0  0.0   0.0  0.0  \n",
       "2     0.0  0.0   0.0  0.0  \n",
       "3     0.0  0.0   0.0  0.0  \n",
       "4     0.0  0.0   0.0  0.0  \n",
       "\n",
       "[5 rows x 501 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idaviso</th>\n",
       "      <th>estas</th>\n",
       "      <th>interes</th>\n",
       "      <th>grup</th>\n",
       "      <th>ingres</th>\n",
       "      <th>dat</th>\n",
       "      <th>vincul</th>\n",
       "      <th>industri</th>\n",
       "      <th>automotriz</th>\n",
       "      <th>estar</th>\n",
       "      <th>...</th>\n",
       "      <th>munr</th>\n",
       "      <th>autogestion</th>\n",
       "      <th>maquinari</th>\n",
       "      <th>we</th>\n",
       "      <th>join</th>\n",
       "      <th>solutix</th>\n",
       "      <th>lectur</th>\n",
       "      <th>it</th>\n",
       "      <th>pyme</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1112408066</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2399</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      idaviso  estas  interes  grup  ingres     dat  vincul  industri  \\\n",
       "2  1112408066    0.0      0.0   0.0     0.0  0.2399     0.0       0.0   \n",
       "\n",
       "   automotriz  estar ...   munr  autogestion  maquinari   we  join  solutix  \\\n",
       "2         0.0    0.0 ...    0.0          0.0        0.0  0.0   0.0      0.0   \n",
       "\n",
       "   lectur   it  pyme  set  \n",
       "2     0.0  0.0   0.0  0.0  \n",
       "\n",
       "[1 rows x 501 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test[\"idaviso\"]==1112408066]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 'are accion comercial sector numer punt estrategi comercial accion comercial estrateg banc financ carg product dat valor asoci sueld'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1.get_group(1112408066)[\"descripcion\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
